{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>–ì–æ—Ä–æ–¥</th>\n",
       "      <th>–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç</th>\n",
       "      <th>–§–ò–û</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–Ω–µ</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–∫–∑</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–≤</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>–ø–∞–∫–µ—Ç</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>—ç–¥–æ</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>—Å–∫—Ä–∏–Ω</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>–Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>–∑–Ω–æ</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>---</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>–æ—à–∏–±–∫–∞</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words –ì–æ—Ä–æ–¥ –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç –§–ò–û\n",
       "1              –Ω–µ     –û          –û   –û\n",
       "2   –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è     –û          –û   –û\n",
       "3              –∫–∑     –û          –û   –û\n",
       "4               –≤     –û          –û   –û\n",
       "5           –ø–∞–∫–µ—Ç     –û          –û   –û\n",
       "6             —ç–¥–æ     –û          –û   –û\n",
       "7           —Å–∫—Ä–∏–Ω     –û          –û   –û\n",
       "8   –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π     –û          –û   –û\n",
       "9             –∑–Ω–æ     –û          –û   –û\n",
       "10            ---     –û          –û   –û\n",
       "11         –æ—à–∏–±–∫–∞     –û          –û   –û"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"NER.xlsx\")\n",
    "df[\"words\"] = df[\"words\"].astype(str)\n",
    "df[1:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä—ã –∫–∞–∂–¥–æ–π –∏–º–µ–Ω–æ–≤–∞–Ω–Ω–æ–π —Å—É—â–Ω–æ—Å—Ç–∏:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>–ì–æ—Ä–æ–¥</th>\n",
       "      <th>–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç</th>\n",
       "      <th>–§–ò–û</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>–æ–æ–æ</td>\n",
       "      <td>–û</td>\n",
       "      <td>–Ω</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>–∞–±—É—Ç–∏–ª–æ–Ω</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>—Å—Ç—Ä–æ–π</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π</td>\n",
       "      <td>–û</td>\n",
       "      <td>–Ω</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>–∞–≥–∞–≤–∞</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>–≥–∞–±–æ–≤</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>–∏–≤–∞–Ω</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>–º–∏—Ö–∞–π–ª–æ–≤–∏—á</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>–∏–ø</td>\n",
       "      <td>–û</td>\n",
       "      <td>–Ω</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>–∞–≥–∞–ø–∞–Ω—Ç—É—Å</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               words –ì–æ—Ä–æ–¥ –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç –§–ò–û\n",
       "365              –æ–æ–æ     –û          –Ω   –û\n",
       "366         –∞–±—É—Ç–∏–ª–æ–Ω     –û          –ø   –û\n",
       "367            —Å—Ç—Ä–æ–π     –û          –ø   –û\n",
       "463   –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π     –û          –Ω   –û\n",
       "464            –∞–≥–∞–≤–∞     –û          –ø   –û\n",
       "465            –≥–∞–±–æ–≤     –û          –ø   –û\n",
       "466             –∏–≤–∞–Ω     –û          –ø   –û\n",
       "467       –º–∏—Ö–∞–π–ª–æ–≤–∏—á     –û          –ø   –û\n",
       "1033              –∏–ø     –û          –Ω   –û\n",
       "1034       –∞–≥–∞–ø–∞–Ω—Ç—É—Å     –û          –ø   –û"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç\"] != \"–û\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –§–∞–º–∏–ª–∏—è, –∏–º—è –∏ –æ—Ç—á–µ—Å—Ç–≤–æ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>–ì–æ—Ä–æ–¥</th>\n",
       "      <th>–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç</th>\n",
       "      <th>–§–ò–û</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>–ø—Ä–∏—â–µ–ø–æ–≤–∞</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–Ω</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>–∞–ª—å–±–∏–Ω–∞</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>–º–∞–∑–∏—Ç–æ–≤–æ–π</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–Ω</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>–º–∞–∫–∞—Ä–æ–≤–∞</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–Ω</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>–∏–ª—å–±–∞–µ–≤</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–Ω</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>—Ö–∞–ª–∏—Ç</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>–∞–±–¥—É–ª—Ö–∞–±–∏—Ä–æ–≤–∏—á</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>–∫–æ–ø—Ç—è–µ–≤–∞</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–Ω</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>–∞—Ñ–∞–Ω–≤—Å—å–µ–≤–∞</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–Ω</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>–∞–Ω–∞—Ç–æ–ª–∏—è</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–ø</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               words –ì–æ—Ä–æ–¥ –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç –§–ò–û\n",
       "319        –ø—Ä–∏—â–µ–ø–æ–≤–∞     –û          –û   –Ω\n",
       "320          –∞–ª—å–±–∏–Ω–∞     –û          –û   –ø\n",
       "654        –º–∞–∑–∏—Ç–æ–≤–æ–π     –û          –û   –Ω\n",
       "1076        –º–∞–∫–∞—Ä–æ–≤–∞     –û          –û   –Ω\n",
       "1847         –∏–ª—å–±–∞–µ–≤     –û          –û   –Ω\n",
       "1848           —Ö–∞–ª–∏—Ç     –û          –û   –ø\n",
       "1849  –∞–±–¥—É–ª—Ö–∞–±–∏—Ä–æ–≤–∏—á     –û          –û   –ø\n",
       "3687        –∫–æ–ø—Ç—è–µ–≤–∞     –û          –û   –Ω\n",
       "3694      –∞—Ñ–∞–Ω–≤—Å—å–µ–≤–∞     –û          –û   –Ω\n",
       "3695        –∞–Ω–∞—Ç–æ–ª–∏—è     –û          –û   –ø"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"–§–ò–û\"] != \"–û\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –ì–æ—Ä–æ–¥:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>–ì–æ—Ä–æ–¥</th>\n",
       "      <th>–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç</th>\n",
       "      <th>–§–ò–û</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>–º–æ—Å–∫–≤–∞</td>\n",
       "      <td>–Ω</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫</td>\n",
       "      <td>–Ω</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6918</th>\n",
       "      <td>–∞—Å—Ç—Ä–∞—Ö–∞–Ω–∏</td>\n",
       "      <td>–Ω</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6940</th>\n",
       "      <td>—Å–∞–º–∞—Ä—É</td>\n",
       "      <td>–Ω</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>–∫–∞–Ω—Å–∫</td>\n",
       "      <td>–Ω</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12848</th>\n",
       "      <td>–Ω–∏–∂–Ω–∏–π</td>\n",
       "      <td>–Ω</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12849</th>\n",
       "      <td>–Ω–æ–≤–≥–æ—Ä–æ–¥</td>\n",
       "      <td>–ø</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12852</th>\n",
       "      <td>–Ω–∏–∂–Ω–∏–π</td>\n",
       "      <td>–Ω</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12853</th>\n",
       "      <td>–Ω–æ–≤–≥–æ—Ä–æ–¥</td>\n",
       "      <td>–ø</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words –ì–æ—Ä–æ–¥ –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç –§–ò–û\n",
       "377        –º–æ—Å–∫–≤–∞     –Ω          –û   –û\n",
       "2355   –∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫     –Ω          –û   –û\n",
       "6918    –∞—Å—Ç—Ä–∞—Ö–∞–Ω–∏     –Ω          –û   –û\n",
       "6940       —Å–∞–º–∞—Ä—É     –Ω          –û   –û\n",
       "10198       –∫–∞–Ω—Å–∫     –Ω          –û   –û\n",
       "12848      –Ω–∏–∂–Ω–∏–π     –Ω          –û   –û\n",
       "12849    –Ω–æ–≤–≥–æ—Ä–æ–¥     –ø          –û   –û\n",
       "12852      –Ω–∏–∂–Ω–∏–π     –Ω          –û   –û\n",
       "12853    –Ω–æ–≤–≥–æ—Ä–æ–¥     –ø          –û   –û"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"–ì–æ—Ä–æ–¥\"] != \"–û\"][:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>–ì–æ—Ä–æ–¥</th>\n",
       "      <th>–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç</th>\n",
       "      <th>–§–ò–û</th>\n",
       "      <th>sent_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>–Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>–∑–Ω–æ</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>---</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>–æ—à–∏–±–∫–∞</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>–ø—Ä–∏</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words –ì–æ—Ä–æ–¥ –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç –§–ò–û  sent_number\n",
       "8   –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π     –û          –û   –û            0\n",
       "9             –∑–Ω–æ     –û          –û   –û            0\n",
       "10            ---     –û          –û   –û            1\n",
       "11         –æ—à–∏–±–∫–∞     –û          –û   –û            1\n",
       "12            –ø—Ä–∏     –û          –û   –û            1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sent_number\"] = (df[\"words\"] == \"---\").astype(int).cumsum()\n",
    "df[8:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "lemmatizer = MorphAnalyzer()\n",
    "to_normal_form = { word : lemmatizer.normal_forms(word) for word in df[\"words\"].unique() }\n",
    "df[\"words\"] = df[\"words\"].apply(lambda x : to_normal_form[x][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>–ì–æ—Ä–æ–¥</th>\n",
       "      <th>–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç</th>\n",
       "      <th>–§–ò–û</th>\n",
       "      <th>sent_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–¥–¥</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–Ω–µ</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ø–æ–¥—Ç—è–≥–∏–≤–∞—Ç—å—Å—è</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–∫–∑</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–≤</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>–û</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words –ì–æ—Ä–æ–¥ –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç –§–ò–û  sent_number\n",
       "0             –¥–¥     –û          –û   –û            0\n",
       "1             –Ω–µ     –û          –û   –û            0\n",
       "2  –ø–æ–¥—Ç—è–≥–∏–≤–∞—Ç—å—Å—è     –û          –û   –û            0\n",
       "3             –∫–∑     –û          –û   –û            0\n",
       "4              –≤     –û          –û   –û            0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ =====\n",
      "df_train.shape: (639058, 5)\n",
      "df_dev.shape: (159765, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_dev = train_test_split(df, test_size=0.2)\n",
    "print(\"===== –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ =====\")\n",
    "print(\"df_train.shape:\", df_train.shape)\n",
    "print(\"df_dev.shape:\", df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ë–∞–∑–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–∞–∑–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–æ –≤ –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–∏ —Ç–µ–≥–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Å–ª–æ–≤ –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –º–Ω–æ–∂–µ—Å—Ç–≤–∞. –ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ:\n",
    "- –î–ª—è –∫–∞–∂–¥–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞ —Ö—Ä–∞–Ω–∏–º —Å–ª–æ–≤–∞—Ä—å, –≤ –∫–æ—Ç–æ—Ä–æ–º –∑–∞–ø–∏—Å—ã–≤–∞–µ–º, —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ –≤—Å—Ç—Ä–µ—á–∞–ª–∏—Å—å –º–µ—Ç–∫–∏ $–û$, $–Ω$ –∏ $–ø$\n",
    "- –ó–∞–ø–æ–º–∏–Ω–∞–µ–º —Å–∞–º—É—é —á–∞—Å—Ç–æ—Ç–Ω—É—é –º–µ—Ç–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞\n",
    "- –í–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –≤—ã–¥–∞–µ–º —Å–∞–º—É—é —á–∞—Å—Ç–æ—Ç–Ω—É—é –º–µ—Ç–∫—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "class BasicModel(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        words = Series(X).unique().tolist()\n",
    "        self.vocabulary = {word : {\"–û\" : 0, \"–Ω\" : 0, \"–ø\" : 0} for word in words}\n",
    "        for word, entity in zip(X, y):\n",
    "            self.vocabulary[word][entity] += 1\n",
    "\n",
    "        self.memory = {}\n",
    "        for key, dictionary in self.vocabulary.items():\n",
    "            self.memory[key] = max(dictionary, key=dictionary.get)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "\n",
    "        return [self.memory.get(x, '–û') for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç =====\n",
      "precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.4157303370786517\n",
      "precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.06299212598425197\n",
      "recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.7254901960784313\n",
      "recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.8\n",
      "===== –ì–æ—Ä–æ–¥ =====\n",
      "precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.8035714285714286\n",
      "precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.5675675675675675\n",
      "recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.8587786259541985\n",
      "recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.9545454545454546\n",
      "===== –§–ò–û =====\n",
      "precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.5404290429042904\n",
      "precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.845564773452457\n",
      "recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.8768406961178046\n",
      "recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.9137931034482759\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_train = df_train[\"words\"].values.tolist()\n",
    "X_dev = df_dev[\"words\"].values.tolist()\n",
    "for name in [\"–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç\", \"–ì–æ—Ä–æ–¥\", \"–§–ò–û\"]:\n",
    "    y_train = df_train[name].values.tolist()\n",
    "    y_dev = df_dev[name].values.tolist()\n",
    "    basic_model = BasicModel()\n",
    "    basic_model.fit(X_train, y_train)\n",
    "    print(\"=====\", name, \"=====\")\n",
    "    print(\"precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏):\", precision_score(basic_model.predict(X_dev), y_dev, average=None)[1])\n",
    "    print(\"precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏):\", precision_score(basic_model.predict(X_dev), y_dev, average=None)[2])\n",
    "    print(\"recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏):\", recall_score(basic_model.predict(X_dev), y_dev, average=None)[1])\n",
    "    print(\"recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏):\", recall_score(basic_model.predict(X_dev), y_dev, average=None)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ù–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–∂–¥–µ —á–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∫–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É –∏–∑ –≤—ã–±–æ—Ä–∫–∏ (–≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ –æ–±—ä–µ–∫—Ç—ã - —ç—Ç–æ —Å–ª–æ–≤–∞) —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ. –ö–∞–∂–¥–æ–º—É —Å–ª–æ–≤—É –±—É–¥–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è—Ç—å —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:\n",
    "- –¥–ª–∏–Ω—É —Å–ª–æ–≤–∞\n",
    "- —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ —á–∏—Å–ª–æ–º\n",
    "- —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å–ª–æ–≤–æ —Å–∏–º–≤–æ–ª—ã, –æ—Ç–ª–∏—á–Ω—ã–µ –æ—Ç –±—É–∫–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_map(word):\n",
    "    \n",
    "    return np.array([len(word), word.isdigit(), word.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [feature_map(w) for w in df_train[\"words\"].values.tolist()]\n",
    "X_dev = [feature_map(w) for w in df_dev[\"words\"].values.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –º—ã –º–æ–∂–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏. –ù–∞—á–µ–º —Å–æ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞ –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –µ–≥–æ —Ä–∞–±–æ—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∏–º–µ–Ω–æ–≤–∞–Ω–Ω–æ–π —Å—É—â–Ω–æ—Å—Ç–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç =====\n",
      "precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.5730337078651685\n",
      "precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.7952755905511811\n",
      "recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.0024182076813655763\n",
      "recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.0013928152795973246\n",
      "===== –ì–æ—Ä–æ–¥ =====\n",
      "precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.95\n",
      "precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.0\n",
      "recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.003025512119109635\n",
      "recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.0\n",
      "===== –§–ò–û =====\n",
      "precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.4744224422442244\n",
      "precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.7402680280791321\n",
      "recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.01468485034222086\n",
      "recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.01394381603779255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for name in [\"–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç\", \"–ì–æ—Ä–æ–¥\", \"–§–ò–û\"]:\n",
    "    y_train = df_train[name].values.tolist()\n",
    "    y_dev = df_dev[name].values.tolist()\n",
    "    model = RandomForestClassifier(ùëêùëôùëéùë†ùë†_ùë§ùëíùëñùëî‚Ñéùë° ={\"–û\" : 1, \"–Ω\" : 1000, \"–ø\" : 1000})\n",
    "    model.fit(X_train, y_train)\n",
    "    rf_prediction = model.predict(X_dev)\n",
    "    print(\"=====\", name, \"=====\")\n",
    "    print(\"precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏):\", precision_score(rf_prediction, y_dev, average=None)[1])\n",
    "    print(\"precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏):\", precision_score(rf_prediction, y_dev, average=None)[2])\n",
    "    print(\"recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏):\", recall_score(rf_prediction, y_dev, average=None)[1])\n",
    "    print(\"recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏):\", recall_score(rf_prediction, y_dev, average=None)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç =====\n",
      "precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.7191011235955056\n",
      "precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.6220472440944882\n",
      "recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.0013076168682576005\n",
      "recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.0013458950201884253\n",
      "===== –ì–æ—Ä–æ–¥ =====\n",
      "precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.9964285714285714\n",
      "precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.0\n",
      "recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.0024024386043467777\n",
      "recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.0\n",
      "===== –§–ò–û =====\n",
      "precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.4777227722772277\n",
      "precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.7453733248245055\n",
      "recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏): 0.01252650253126217\n",
      "recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏): 0.011857747637079826\n"
     ]
    }
   ],
   "source": [
    "for name in [\"–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç\", \"–ì–æ—Ä–æ–¥\", \"–§–ò–û\"]:\n",
    "    y_train = df_train[name].values.tolist()\n",
    "    y_dev = df_dev[name].values.tolist()\n",
    "    model = LogisticRegression(solver='lbfgs',ùëêùëôùëéùë†ùë†_ùë§ùëíùëñùëî‚Ñéùë° ={\"–û\" : 1, \"–Ω\" : 1000, \"–ø\" : 1000})\n",
    "    model.fit(X_train, y_train)\n",
    "    lr_prediction = model.predict(X_dev)\n",
    "    print(\"=====\", name, \"=====\")\n",
    "    print(\"precision_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏):\", precision_score(lr_prediction, y_dev, average=None)[1])\n",
    "    print(\"precision_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏):\", precision_score(lr_prediction, y_dev, average=None)[2])\n",
    "    print(\"recall_score (–Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏):\", recall_score(lr_prediction, y_dev, average=None)[1])\n",
    "    print(\"recall_score (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏):\", recall_score(lr_prediction, y_dev, average=None)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å, —É—á–∏—Ç—ã–≤–∞—é—â—É—é –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏, —Ç–∞–∫ —á—Ç–æ —Å—Ç–∞—Ä—ã–π –ø–æ–¥—Ö–æ–¥, –∫–æ–≥–¥–∞ –º—ã –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ —Å–ª–æ–≤–∞–º –∏ —Ä–∞–∑–±–∏–≤–∞–ª–∏ –≤—ã–±–æ—Ä–∫—É –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –æ—Ç–ª–æ–∂–µ–Ω–Ω—É—é –Ω–µ –∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∏—Ö —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ, —É–∂–µ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Å—É—â–Ω–æ—Å—Ç–∏ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:\n",
    "- –†–∞–∑–æ–±—å–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (—É—á–∏—Ç—ã–≤–∞—è –ø–æ–ª–µ $sent\\_number$)\n",
    "- –ö–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–º —Å–ø–∏—Å–∫–æ–º –ø–∞—Ä $(word, entity)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [\"–§–ò–û\", \"–ì–æ—Ä–æ–¥\", \"–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç\"]:\n",
    "    get_pair_func = lambda s: [(word, entity) for word, entity in zip(s[\"words\"].values.tolist(),\n",
    "                                                                      s[name].values.tolist())]\n",
    "    grouped_words = df.groupby(\"sent_number\").apply(get_pair_func)\n",
    "    sentences[name] = [sentence for sentence in grouped_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('–¥–¥', '–û'),\n",
       "  ('–Ω–µ', '–û'),\n",
       "  ('–ø–æ–¥—Ç—è–≥–∏–≤–∞—Ç—å—Å—è', '–û'),\n",
       "  ('–∫–∑', '–û'),\n",
       "  ('–≤', '–û'),\n",
       "  ('–ø–∞–∫–µ—Ç', '–û'),\n",
       "  ('—ç–¥–æ', '–û'),\n",
       "  ('—Å–∫—Ä–∏–Ω', '–û'),\n",
       "  ('–Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π', '–û'),\n",
       "  ('–∑–Ω–æ', '–û')]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[\"–§–ò–û\"][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18514, 4629)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences = {}\n",
    "dev_sentences = {}\n",
    "for name in [\"–§–ò–û\", \"–ì–æ—Ä–æ–¥\", \"–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç\"]:\n",
    "    train_sentences[name], dev_sentences[name] = train_test_split(sentences[name], test_size=0.2)\n",
    "len(train_sentences[name]), len(dev_sentences[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"–§–ò–û\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 50\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "words = list(set(df[\"words\"].values))\n",
    "tags = list(set(df[name].values))\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {\"–û\" : 0, \"–Ω\" : 1, \"–ø\" : 2}\n",
    "\n",
    "def sentences2X(sentences):\n",
    "    X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "    X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding=\"post\",value=len(words) - 1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def sentences2y(sentences):\n",
    "    y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "    y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx['–û'])\n",
    "    y = [to_categorical(i, num_classes=len(tags)) for i in y]\n",
    "    \n",
    "    return np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = sentences2X(train_sentences[name])\n",
    "X_dev = sentences2X(dev_sentences[name])\n",
    "y_train = sentences2y(train_sentences[name])\n",
    "y_dev = sentences2y(dev_sentences[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $begin\\_recall$ - $Recall$ –¥–ª—è –º–µ—Ç–∫–∏ $–Ω$\n",
    "- $continuous\\_recall$ - $Recall$ –¥–ª—è –º–µ—Ç–∫–∏ $–ø$\n",
    "- $begin\\_precision$ - $Precision$ –¥–ª—è –º–µ—Ç–∫–∏ $–Ω$\n",
    "- $continuous\\_precision$ - $Precision$ –¥–ª—è –º–µ—Ç–∫–∏ $–ø$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPS=1e-10\n",
    "def begin_recall(y_true, y_pred):\n",
    "    \n",
    "    return tf.reduce_sum(y_true[::, ::, 1] * y_pred[::, ::, 1]) / (tf.reduce_sum(y_true[::, ::, 1]) + EPS)\n",
    "def continuous_recall(y_true, y_pred):\n",
    "    \n",
    "    return tf.reduce_sum(y_true[::, ::, 2] * y_pred[::, ::, 2]) / (tf.reduce_sum(y_true[::, ::, 2]) + EPS)\n",
    "def begin_precision(y_true, y_pred):\n",
    "    \n",
    "    return tf.reduce_sum(y_true[::, ::, 1] * y_pred[::, ::, 1]) / (tf.reduce_sum(y_pred[::, ::, 1]) + EPS)\n",
    "def continuous_precision(y_true, y_pred):\n",
    "    \n",
    "    return tf.reduce_sum(y_true[::, ::, 2] * y_pred[::, ::, 2]) / (tf.reduce_sum(y_pred[::, ::, 2]) + EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å—Ç—Ä–æ–∏–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 50)            1833650   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 50)            0         \n",
      "_________________________________________________________________\n",
      "rnn_1 (RNN)                  (None, 50, 100)           15100     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 3)             303       \n",
      "=================================================================\n",
      "Total params: 1,849,053\n",
      "Trainable params: 1,849,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.layers as L\n",
    "from keras.models import Model\n",
    "\n",
    "layer_input = L.Input(shape=(MAX_LEN,))\n",
    "layer_emb = L.Embedding(input_dim=len(words), output_dim=MAX_LEN, input_length=MAX_LEN)(layer_input)\n",
    "layer_drop = L.Dropout(0.1)(layer_emb)\n",
    "layer_lstm = L.RNN(L.SimpleRNNCell(units=100), return_sequences=True)(layer_drop)\n",
    "layer_output = L.TimeDistributed(L.Dense(len(tags), activation=\"softmax\"))(layer_lstm)\n",
    "model = Model(layer_input, layer_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=[begin_recall, continuous_recall, begin_precision, continuous_precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18514 samples, validate on 4629 samples\n",
      "Epoch 1/5\n",
      "18514/18514 [==============================] - 47s 3ms/step - loss: 0.0363 - begin_recall: 0.2701 - continuous_recall: 0.4892 - begin_precision: 0.2375 - continuous_precision: 0.4597 - val_loss: 0.0119 - val_begin_recall: 0.4560 - val_continuous_recall: 0.7221 - val_begin_precision: 0.5257 - val_continuous_precision: 0.7223\n",
      "Epoch 2/5\n",
      "18514/18514 [==============================] - 46s 2ms/step - loss: 0.0062 - begin_recall: 0.7674 - continuous_recall: 0.7863 - begin_precision: 0.7390 - continuous_precision: 0.7797 - val_loss: 0.0110 - val_begin_recall: 0.5564 - val_continuous_recall: 0.7376 - val_begin_precision: 0.6110 - val_continuous_precision: 0.7708\n",
      "Epoch 3/5\n",
      "18514/18514 [==============================] - 47s 3ms/step - loss: 0.0035 - begin_recall: 0.8759 - continuous_recall: 0.7967 - begin_precision: 0.8659 - continuous_precision: 0.7928 - val_loss: 0.0117 - val_begin_recall: 0.5377 - val_continuous_recall: 0.7063 - val_begin_precision: 0.6382 - val_continuous_precision: 0.7804\n",
      "Epoch 4/5\n",
      "18514/18514 [==============================] - 47s 3ms/step - loss: 0.0027 - begin_recall: 0.9011 - continuous_recall: 0.8321 - begin_precision: 0.8942 - continuous_precision: 0.8266 - val_loss: 0.0127 - val_begin_recall: 0.6094 - val_continuous_recall: 0.7130 - val_begin_precision: 0.5682 - val_continuous_precision: 0.7149\n",
      "Epoch 5/5\n",
      "18514/18514 [==============================] - 47s 3ms/step - loss: 0.0022 - begin_recall: 0.9120 - continuous_recall: 0.8467 - begin_precision: 0.9046 - continuous_precision: 0.8434 - val_loss: 0.0154 - val_begin_recall: 0.5676 - val_continuous_recall: 0.7465 - val_begin_precision: 0.6160 - val_continuous_precision: 0.7284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17d00f60>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, np.array(y_train), \n",
    "          batch_size=16, \n",
    "          epochs=5,\n",
    "          validation_data = (X_dev, np.array(y_dev)),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_input = L.Input(shape=(MAX_LEN,))\n",
    "layer_emb = L.Embedding(input_dim=len(words), output_dim=MAX_LEN, input_length=MAX_LEN)(layer_input)\n",
    "layer_drop = L.Dropout(0.1)(layer_emb)\n",
    "layer_lstm = L.LSTM(128, return_sequences=True)(layer_drop)\n",
    "layer_output = L.TimeDistributed(L.Dense(len(tags), activation=\"softmax\"))(layer_lstm)\n",
    "model = Model(layer_input, layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=[begin_recall, continuous_recall, begin_precision, continuous_precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18514 samples, validate on 4629 samples\n",
      "Epoch 1/5\n",
      "18514/18514 [==============================] - 80s 4ms/step - loss: 0.0391 - begin_recall: 0.2272 - continuous_recall: 0.5082 - begin_precision: 0.1998 - continuous_precision: 0.4768 - val_loss: 0.0114 - val_begin_recall: 0.5404 - val_continuous_recall: 0.7400 - val_begin_precision: 0.4312 - val_continuous_precision: 0.6921\n",
      "Epoch 2/5\n",
      "18514/18514 [==============================] - 76s 4ms/step - loss: 0.0063 - begin_recall: 0.7619 - continuous_recall: 0.7674 - begin_precision: 0.7366 - continuous_precision: 0.7511 - val_loss: 0.0120 - val_begin_recall: 0.5122 - val_continuous_recall: 0.7220 - val_begin_precision: 0.5982 - val_continuous_precision: 0.7429\n",
      "Epoch 3/5\n",
      "18514/18514 [==============================] - 77s 4ms/step - loss: 0.0037 - begin_recall: 0.8899 - continuous_recall: 0.8171 - begin_precision: 0.8783 - continuous_precision: 0.8111 - val_loss: 0.0138 - val_begin_recall: 0.6856 - val_continuous_recall: 0.8107 - val_begin_precision: 0.4752 - val_continuous_precision: 0.5969\n",
      "Epoch 4/5\n",
      "18514/18514 [==============================] - 78s 4ms/step - loss: 0.0030 - begin_recall: 0.9014 - continuous_recall: 0.8293 - begin_precision: 0.8963 - continuous_precision: 0.8201 - val_loss: 0.0127 - val_begin_recall: 0.6803 - val_continuous_recall: 0.7655 - val_begin_precision: 0.4852 - val_continuous_precision: 0.7109\n",
      "Epoch 5/5\n",
      "18514/18514 [==============================] - 78s 4ms/step - loss: 0.0025 - begin_recall: 0.8969 - continuous_recall: 0.8298 - begin_precision: 0.8921 - continuous_precision: 0.8261 - val_loss: 0.0136 - val_begin_recall: 0.7153 - val_continuous_recall: 0.7756 - val_begin_precision: 0.4420 - val_continuous_precision: 0.7412\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, np.array(y_train), \n",
    "          batch_size=16, \n",
    "          epochs=5,\n",
    "          validation_data = (X_dev, np.array(y_dev)),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
